#!/usr/bin/env python3
"""Auto-generate README.md from pyproject.toml and installed packages."""

import subprocess
from pathlib import Path

try:
    import tomllib
except ImportError:
    import tomli as tomllib


def get_direct_dependencies():
    """Extract direct dependencies from pyproject.toml"""
    pyproject_path = Path(__file__).parent.parent / "pyproject.toml"
    with open(pyproject_path, "rb") as f:
        data = tomllib.load(f)

    return data.get("project", {}).get("dependencies", [])


def get_all_installed_packages():
    """Get all installed packages from uv pip list"""
    try:
        result = subprocess.run(
            ["uv", "pip", "list", "--format=columns"],
            capture_output=True,
            text=True,
            check=True
        )

        if result.stdout:
            lines = result.stdout.strip().split("\n")
            # Skip header lines
            package_lines = [line for line in lines[2:] if line.strip()]
            packages = []

            for line in package_lines:
                parts = line.split()
                if len(parts) >= 2:
                    packages.append((parts[0], parts[1]))

            return packages
    except Exception as e:
        print(f"Warning: Could not get package list: {e}")
        return []


def generate_readme():
    """Generate README.md content"""
    direct_deps = get_direct_dependencies()
    all_packages = get_all_installed_packages()

    readme_content = f"""# ApexML - F1 Race Analytics Platform

A comprehensive data engineering platform for Formula 1 race analytics using OpenF1 API, Snowflake, dbt, and Streamlit.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Terraform](https://img.shields.io/badge/Terraform-1.6+-purple.svg)](https://www.terraform.io/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.51+-red.svg)](https://streamlit.io/)
[![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Warehouse-29B5E8.svg)](https://www.snowflake.com/)

---

## ğŸ¯ Project Overview

ApexML is a comprehensive data engineering platform that:

- **Extracts** real-time Formula 1 data from the OpenF1 API
- **Loads** data into Snowflake data warehouse (RAW schema)
- **Transforms** data using dbt (STAGING â†’ ANALYTICS schemas)
- **Tests** data quality with automated dbt tests
- **Visualizes** insights through an interactive Streamlit dashboard

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODERN DATA ENGINEERING ARCHITECTURE (ELT)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ DATA INGESTION (Extract & Load)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  OpenF1 API  â”‚  â† Real-time F1 data (REST API)
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“ httpx
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ extract.py   â”‚  â† Python ELT script
   â”‚ load.py      â”‚  â† Loads to Snowflake RAW schema
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
2ï¸âƒ£ DATA WAREHOUSE (Snowflake)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚         APEXML_DEV Database            â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  ğŸ“ RAW Schema                         â”‚
   â”‚    â€¢ sessions   (raw API data)         â”‚
   â”‚    â€¢ drivers    (raw API data)         â”‚
   â”‚    â€¢ positions  (raw API data)         â”‚
   â”‚    â€¢ laps       (raw API data)         â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚           â†“ dbt transformations        â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  ğŸ“ STAGING Schema (views)             â”‚
   â”‚    â€¢ stg_sessions   (cleaned)          â”‚
   â”‚    â€¢ stg_drivers    (deduplicated)     â”‚
   â”‚    â€¢ stg_laps       (validated)        â”‚
   â”‚    â€¢ stg_positions  (filtered)         â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚           â†“ dbt transformations        â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  ğŸ“ ANALYTICS Schema (tables)          â”‚
   â”‚    â€¢ dim_drivers        (dimension)    â”‚
   â”‚    â€¢ fct_lap_times      (fact)         â”‚
   â”‚    â€¢ fct_race_results   (fact)         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
3ï¸âƒ£ TRANSFORMATION (dbt)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  dbt Core    â”‚  â† SQL-based transformations
   â”‚              â”‚  â† Data quality tests (22 passing)
   â”‚  â€¢ Models    â”‚  â† RAW â†’ STAGING â†’ ANALYTICS
   â”‚  â€¢ Tests     â”‚  â† not_null, unique, custom
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
4ï¸âƒ£ VISUALIZATION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Streamlit   â”‚  â† Interactive dashboard
   â”‚  Dashboard   â”‚  â† Queries ANALYTICS schema
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
5ï¸âƒ£ INFRASTRUCTURE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Terraform   â”‚  â† Infrastructure as Code (IaC)
   â”‚              â”‚  â† Snowflake resources
   â”‚              â”‚  â† Multi-environment (dev/staging/prod)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

**Data Ingestion:** OpenF1 API, Python 3.11+, httpx, snowflake-connector-python
**Transformation:** dbt Core, dbt-snowflake (SQL-based ELT)
**Data Warehouse:** Snowflake (RAW â†’ STAGING â†’ ANALYTICS schemas)
**Visualization:** Streamlit
**Infrastructure:** Terraform (IaC)
**Package Manager:** uv (fast Python package manager)
**Testing:** pytest
**CI/CD:** GitHub Actions

---

## ğŸ“¦ Dependencies

Managed with **uv** package manager (see [pyproject.toml](pyproject.toml))

### Direct Dependencies

```
{chr(10).join(direct_deps)}
```

### All Installed Packages ({len(all_packages)} total)

<details>
<summary>View all packages</summary>

```
{chr(10).join(f"{name:<40} {version}" for name, version in all_packages)}
```

</details>

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11-3.13
- uv package manager
- Snowflake account
- Terraform

### Installation

```bash
# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repository
git clone <your-repo-url>
cd apex-ml

# Install dependencies
uv sync
```

### Running the Pipeline

```bash
# 1. Deploy Snowflake infrastructure
cd infra/snowflake
terraform init
terraform apply -var="environment=dev"

# 2. Run data extraction and loading
cd ../..
uv run python snowflake/elt/load.py <session_key>

# 3. Run dbt transformations
./scripts/run_dbt.sh

# 4. Run dbt tests
cd snowflake/dbt_project
uv run dbt test

# 5. Launch Streamlit dashboard
cd ../..
uv run streamlit run app/app.py
```

---

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run API tests
uv run pytest tests/test_api.py -v

# Run dbt tests
cd snowflake/dbt_project
uv run dbt test
```

---

## ğŸ“ Project Structure

```
apex-ml/
â”œâ”€â”€ app/                      # Streamlit dashboard
â”œâ”€â”€ snowflake/
â”‚   â”œâ”€â”€ dbt_project/          # dbt transformations
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ sources/      # Source definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ staging/      # Staging views
â”‚   â”‚   â”‚   â””â”€â”€ analytics/    # Analytics tables
â”‚   â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”‚   â””â”€â”€ profiles.yml
â”‚   â”œâ”€â”€ elt/                  # Data pipeline scripts
â”‚   â”‚   â”œâ”€â”€ extract.py
â”‚   â”‚   â””â”€â”€ load.py
â”‚   â””â”€â”€ config/               # Snowflake configs
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ snowflake/            # Terraform infrastructure
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ grants.tf
â”‚       â””â”€â”€ tables.tf
â”œâ”€â”€ scripts/                  # Shell scripts
â”‚   â”œâ”€â”€ run_dbt.sh
â”‚   â””â”€â”€ setup_snowflake_keypair.sh
â”œâ”€â”€ tests/                    # Test files
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ ml/                       # ML models (future)
â””â”€â”€ pyproject.toml            # Dependencies & config
```

---

## ğŸ” Security

- Uses JWT authentication for Snowflake
- Private keys stored securely (not in repo)
- Environment variables for sensitive data
- Terraform state encryption

---

## ğŸ‘¨â€ğŸ’» Author

**Flavia Ferreira**
- GitHub: [@youngpada1](https://github.com/youngpada1)
- Email: flavsferr@gmail.com

---

**Built with â¤ï¸ using Python, Terraform, Snowflake, and dbt**

_README auto-generated via GitHub Actions_
"""

    # Write to README.md
    readme_path = Path(__file__).parent.parent / "README.md"
    with open(readme_path, "w") as f:
        f.write(readme_content)

    print("âœ“ README.md generated successfully")
    print(f"âœ“ Direct dependencies: {len(direct_deps)}")
    print(f"âœ“ Total packages: {len(all_packages)}")


if __name__ == "__main__":
    generate_readme()
