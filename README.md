# ApexML - F1 Race Analytics & Prediction Platform

> An end-to-end data engineering and ML platform for Formula 1 race analytics, predictions, and visualizations.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![Terraform](https://img.shields.io/badge/Terraform-1.6+-purple.svg)](https://www.terraform.io/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.51+-red.svg)](https://streamlit.io/)
[![Snowflake](https://img.shields.io/badge/Snowflake-Data%20Warehouse-29B5E8.svg)](https://www.snowflake.com/)
[![AWS](https://img.shields.io/badge/AWS-EC2-orange.svg)](https://aws.amazon.com/)

---

## ğŸ“‹ Table of Contents

- [Project Overview](#-project-overview)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Setup & Installation](#-setup--installation)
- [Infrastructure](#-infrastructure)
- [Data Pipeline](#-data-pipeline)
- [ML Model](#-ml-model)
- [Deployment](#-deployment)
- [CI/CD](#-cicd)
- [Future Enhancements](#-future-enhancements)

---

## ğŸ¯ Project Overview

ApexML is a comprehensive data engineering and machine learning platform that:

- **Extracts** real-time Formula 1 data from the OpenF1 API
- **Transforms** and loads data into Snowflake data warehouse
- **Analyzes** historical race performance and driver statistics
- **Predicts** race outcomes using machine learning models
- **Visualizes** insights through an interactive Streamlit dashboard
- **Deploys** on AWS infrastructure with full CI/CD automation

This project demonstrates proficiency in:
- Data Engineering (ETL pipelines, data warehousing)
- DevOps (IaC, containerization, CI/CD)
- Machine Learning (predictive modeling)
- Cloud Infrastructure (AWS EC2, Snowflake)
- Software Engineering best practices

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA ENGINEERING ARCHITECTURE                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ DATA INGESTION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  OpenF1 API  â”‚  â† Real-time F1 data (sessions, drivers, positions)
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ETL Script  â”‚  â† Python (Extract, Transform, Load)
   â”‚  (Scheduled) â”‚  â† Runs daily via GitHub Actions / Cron
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
2ï¸âƒ£ DATA WAREHOUSE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Snowflake   â”‚  â† Centralized data storage
   â”‚              â”‚
   â”‚  Tables:     â”‚
   â”‚  â€¢ sessions  â”‚  â† Race sessions metadata
   â”‚  â€¢ drivers   â”‚  â† Driver information
   â”‚  â€¢ positions â”‚  â† Lap-by-lap positions
   â”‚  â€¢ laps      â”‚  â† Lap times & telemetry
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
3ï¸âƒ£ ANALYTICS & ML
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ML Model    â”‚  â† Trained on historical data
   â”‚  (sklearn)   â”‚  â† Predicts race winners
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
4ï¸âƒ£ VISUALIZATION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Streamlit   â”‚  â† Interactive dashboard
   â”‚  Dashboard   â”‚  â† Connected to Snowflake
   â”‚              â”‚
   â”‚  Features:   â”‚
   â”‚  â€¢ Real-time â”‚  â† Live race data
   â”‚  â€¢ Historicalâ”‚  â† Trends & analytics
   â”‚  â€¢ Predictionsâ”‚ â† ML-powered insights
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
5ï¸âƒ£ INFRASTRUCTURE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  AWS EC2     â”‚  â† Docker container
   â”‚  (t3.micro)  â”‚  â† Hosts Streamlit app
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6ï¸âƒ£ CI/CD & IaC
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Terraform   â”‚  â† Infrastructure as Code
   â”‚              â”‚  â† Multi-environment (dev/staging/prod)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  GitHub      â”‚  â† CI/CD pipelines
   â”‚  Actions     â”‚  â† Automated testing & deployment
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### **Data Engineering**
- **Data Source**: [OpenF1 API](https://openf1.org/) - Real-time Formula 1 data
- **ETL**: Python 3.11+ with `httpx`, `pandas`
- **Data Warehouse**: Snowflake (cloud data platform)
- **Orchestration**: GitHub Actions (scheduled workflows)

### **Machine Learning**
- **Framework**: scikit-learn
- **Model**: Random Forest Classifier (race outcome prediction)
- **Features**: Driver stats, circuit history, qualifying positions

### **Visualization**
- **Frontend**: Streamlit 1.51+
- **Charts**: Altair, Plotly
- **Database Connector**: snowflake-connector-python

### **Infrastructure & DevOps**
- **IaC**: Terraform 1.6+ (workspace-based multi-env)
- **Cloud**: AWS EC2 (t3.micro, free tier)
- **Containerization**: Docker
- **CI/CD**: GitHub Actions
- **Monitoring**: AWS CloudWatch (billing alerts)

### **Development**
- **Version Control**: Git, GitHub
- **Code Quality**: pytest, CodeQL
- **Secrets Management**: GitHub Secrets, Terraform sensitive variables

---

## âœ¨ Features

### **Data Pipeline**
- âœ… Automated daily data ingestion from OpenF1 API
- âœ… ETL pipeline with data validation & transformation
- âœ… Incremental data loading to Snowflake
- âœ… Historical data retention for trend analysis

### **Analytics Dashboard**
- âœ… Real-time race session tracking
- âœ… Historical performance analysis
- âœ… Driver & team comparisons
- âœ… Lap time visualizations
- âœ… Circuit-specific statistics

### **ML Predictions**
- âœ… Race winner prediction based on historical data
- âœ… Driver performance forecasting
- âœ… Confidence scores & probability distributions
- âœ… Model retraining on new data

### **Infrastructure**
- âœ… Multi-environment setup (dev, staging, prod)
- âœ… Terraform workspace-based state management
- âœ… AWS free tier optimization (cost monitoring)
- âœ… Docker containerization for portability
- âœ… Automated deployments via CI/CD

---

## ğŸ“ Project Structure

```
apex-ml/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ codeql.yml              # Security scanning
â”‚       â”œâ”€â”€ generate-readme.yml     # Auto-generate README
â”‚       â””â”€â”€ etl-pipeline.yml        # Scheduled ETL job
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                      # Streamlit dashboard
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_app.py             # Unit tests
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py                  # Fetch data from OpenF1 API
â”‚   â”œâ”€â”€ transform.py                # Data cleaning & validation
â”‚   â”œâ”€â”€ load.py                     # Load to Snowflake
â”‚   â””â”€â”€ config.py                   # ETL configuration
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ train.py                    # Model training
â”‚   â”œâ”€â”€ predict.py                  # Inference
â”‚   â””â”€â”€ model.pkl                   # Trained model
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ main.tf                     # Terraform main config
â”‚   â”œâ”€â”€ variables.tf                # Terraform variables
â”‚   â”œâ”€â”€ outputs.tf                  # Terraform outputs
â”‚   â”œâ”€â”€ billing_alerts.tf.disabled  # AWS billing alerts (optional)
â”‚   â”œâ”€â”€ dev.tfvars                  # Dev environment
â”‚   â”œâ”€â”€ staging.tfvars              # Staging environment
â”‚   â””â”€â”€ prod.tfvars                 # Prod environment
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql                  # Snowflake table definitions
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_readme.py          # Auto-generate README
â”œâ”€â”€ Dockerfile                      # Container definition
â”œâ”€â”€ docker-compose.yml              # Local development
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .dockerignore                   # Docker exclusions
â”œâ”€â”€ .gitignore                      # Git exclusions
â””â”€â”€ README.md                       # Project documentation
```

---

## ğŸš€ Setup & Installation

### **Prerequisites**

- Python 3.11+
- Docker & Docker Compose
- Terraform 1.6+
- AWS Account (free tier)
- Snowflake Account (free trial: $400 credits)
- GitHub Account

### **Local Development**

```bash
# Clone repository
git clone https://github.com/youngpada1/apex-ml.git
cd apex-ml

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run Streamlit locally
streamlit run app/app.py
```

### **Docker Setup**

```bash
# Build image
docker build -t apex-ml:latest .

# Run container
docker run -p 8501:8501 apex-ml:latest

# Or use docker-compose
docker-compose up
```

---

## ğŸ—ï¸ Infrastructure

### **Terraform Workspace Setup**

```bash
cd infra

# Initialize Terraform
terraform init

# Create workspaces
terraform workspace new dev
terraform workspace new staging
terraform workspace new prod

# Deploy to dev
terraform workspace select dev
terraform apply -var-file="dev.tfvars" -var="github_token=$GITHUB_TOKEN"
```

### **Multi-Environment Configuration**

| Environment | Instance Type | Monitoring | Log Retention |
|-------------|--------------|------------|---------------|
| **dev**     | t3.micro     | Disabled   | 7 days        |
| **staging** | t3.micro     | Enabled    | 14 days       |
| **prod**    | t3.micro     | Enabled    | 30 days       |

---

## ğŸ”„ Data Pipeline

### **ETL Process**

```python
# Extract
data = extract_from_openf1_api(
    endpoint="/v1/sessions",
    params={"year": 2025}
)

# Transform
cleaned_data = transform_data(data)
validated_data = validate_schema(cleaned_data)

# Load
load_to_snowflake(
    data=validated_data,
    table="sessions",
    mode="append"
)
```

### **Snowflake Schema**

```sql
-- Sessions
CREATE TABLE sessions (
    session_key INT PRIMARY KEY,
    session_name VARCHAR(100),
    date_start TIMESTAMP,
    circuit_key INT,
    year INT
);

-- Drivers
CREATE TABLE drivers (
    driver_number INT PRIMARY KEY,
    full_name VARCHAR(100),
    team_name VARCHAR(100),
    country_code VARCHAR(3)
);

-- Positions (for ML)
CREATE TABLE positions (
    position_id INT AUTOINCREMENT PRIMARY KEY,
    session_key INT,
    driver_number INT,
    position INT,
    timestamp TIMESTAMP
);
```

---

## ğŸ¤– ML Model

### **Features**

- Driver historical performance
- Circuit-specific statistics
- Qualifying position
- Weather conditions
- Team performance metrics

### **Model Training**

```python
from sklearn.ensemble import RandomForestClassifier

# Load historical data from Snowflake
df = load_training_data()

# Train model
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# Evaluate
accuracy = model.score(X_test, y_test)
print(f"Model Accuracy: {accuracy:.2%}")
```

---

## ğŸš¢ Deployment

### **AWS EC2 Deployment**

1. Provision EC2 instance via Terraform
2. Deploy Docker container
3. Configure security groups
4. Set up Elastic IP (optional)

### **Streamlit Cloud (Alternative)**

```bash
# Deploy to Streamlit Cloud
streamlit deploy app/app.py
```

---

## ğŸ”„ CI/CD

### **GitHub Actions Workflows**

- **CodeQL**: Security scanning on every push
- **README Generation**: Auto-update on file changes
- **ETL Pipeline**: Scheduled daily data ingestion
- **Testing**: Run pytest on PRs
- **Deployment**: Auto-deploy on main branch merge

---

## ğŸ”® Future Enhancements

- [ ] Real-time WebSocket data streaming
- [ ] Advanced ML models (XGBoost, Neural Networks)
- [ ] Multi-model ensemble predictions
- [ ] Historical race replay visualization
- [ ] Driver comparison tool
- [ ] Mobile-responsive dashboard
- [ ] Email alerts for race predictions
- [ ] API endpoint for predictions

---

## ğŸ“Š Project Metrics

- **Data Sources**: 1 (OpenF1 API)
- **Data Tables**: 4+ (Snowflake)
- **ETL Jobs**: 1 (scheduled daily)
- **ML Models**: 1 (Random Forest)
- **Environments**: 3 (dev, staging, prod)
- **CI/CD Pipelines**: 4 (GitHub Actions)
- **Cloud Providers**: 2 (AWS, Snowflake)

---

## ğŸ‘¨â€ğŸ’» Author

**Flavia Ferreira**
- GitHub: [@youngpada1](https://github.com/youngpada1)
- Email: flavsferr@gmail.com

---

## ğŸ“ License

This project is for portfolio demonstration purposes.

---

## ğŸ™ Acknowledgments

- [OpenF1](https://openf1.org/) for providing free F1 data API
- Snowflake for free trial credits
- AWS for free tier resources

---

**Built with â¤ï¸ using Python, Terraform, Snowflake, and AWS**
